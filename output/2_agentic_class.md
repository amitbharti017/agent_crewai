{"title":"Water Usage in Training ChatGPT-3","introduction":"This report examines the water consumption associated with training the GPT-3 language model. The training of large language models like GPT-3 requires substantial computational resources, which in turn consume significant amounts of energy. The generation of this energy, and the cooling of the data centers housing the computing infrastructure, both contribute to water usage.","key_findings":["GPT-3 Training Water Consumption: Estimates suggest that training GPT-3 required between 700,000 liters and 4.8 billion liters of water. This discrepancy likely arises from different methodologies in calculating water usage, including variations in data center efficiency, cooling methods, and energy sources.","Water Usage per Interaction: While the initial training requires a large amount of water, the water usage per user interaction is significantly lower. Estimates vary, with some sources claiming a single ChatGPT request is equivalent to pouring out a bottle of water, while others estimate closer to 5ml per conversation.","Factors Influencing Water Consumption: Data center location, energy source, and cooling technology significantly impact water usage. Data centers in hotter climates require more water for cooling. Power plants, especially thermoelectric plants, can be major water consumers. More efficient cooling systems reduce water consumption.","Comparison to Other Activities: The water used to train GPT-3 is comparable to the water required to produce 100 pounds of beef."],"estimated_water_usage":["700,000 liters (lower estimate for initial training)","4.8 billion liters (higher estimate for initial training)","Varying estimates per user interaction (ranging from a bottle of water to 5ml)"],"factors_influencing_water_usage":["Data Center Location: Data centers in hotter climates require more water for cooling.","Energy Source: Power plants, especially thermoelectric plants, are major water consumers.","Cooling Technology: Inefficient cooling systems increase water consumption."],"mitigation_strategies":["Training AI models during cooler hours can reduce water loss due to evaporation.","Utilizing more efficient data centers.","Employing advanced cooling technologies.","Using renewable energy sources to power data centers."],"contradictory_information":"There are conflicting reports regarding the amount of water consumed per ChatGPT request, with estimates ranging from the equivalent of a full bottle of water to approximately 5ml. The initial training water consumption also varies significantly between 700,000 liters and 4.8 billion liters.","source_references":[{"title":"Interesting Engineering","url":"https://interestingengineering.com/innovation/training-chatgpt-consumes-water"},{"title":"Gizmodo","url":"https://gizmodo.com/chatgpt-ai-water-185000-gallons-training-nuclear-1850324249"},{"title":"The Washington Post","url":"https://www.washingtonpost.com/technology/2024/09/18/energy-ai-use-electricity-water-data-centers/"},{"title":"Reddit","url":"https://www.reddit.com/r/environment/comments/1fmt4wc/now_we_learn_chatgpt_4_model_consumes_up_to_3/"},{"title":"Generative AI Newsroom","url":"https://generative-ai-newsroom.com/the-often-overlooked-water-footprint-of-ai-models-46991e3094b6"},{"title":"Statista","url":"https://www.statista.com/statistics/1536925/gpt-3-estimated-water-consumption-training/"},{"title":"AP News","url":"https://apnews.com/article/chatgpt-gpt4-iowa-ai-water-consumption-microsoft-f551fde98083d17a7e8d904f8be822c4"},{"title":"Sean Goedecke","url":"https://www.seangoedecke.com/water-impact-of-ai/"},{"title":"UCR News","url":"https://news.ucr.edu/articles/2023/04/28/ai-programs-consume-large-volumes-scarce-water"},{"title":"Fortune","url":"https://fortune.com/article/how-much-water-does-ai-use/"},{"title":"TikTok","url":"https://www.tiktok.com/discover/chat-gpt-request-equals-one-bottle-of-water"}],"conclusion":"Training large language models like ChatGPT-3 has a measurable water footprint. While the exact amount varies depending on several factors, it is clear that the water consumption is significant. As AI models continue to grow in size and complexity, it is crucial to develop strategies to mitigate their environmental impact, including reducing water usage through more efficient data centers, cooling technologies, and energy sources. Further research and transparency are needed to accurately assess and address the water footprint of AI."}